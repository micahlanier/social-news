{
 "metadata": {
  "name": "",
  "signature": "sha256:6de8a8f6646a65f6250d9ae49f0c2afb131b9c91cc33e57795827565648ecf6d"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Twitter Hashtags"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This analysis aims to find useful information about Twitter hashtags for pseudo-topic analysis."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Libraries.\n",
      "import json\n",
      "import os\n",
      "import pandas as pd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Settings.\n",
      "twDir = '../../../data/twitter/consolidated/'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Hashtag Contents"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This analysis just reads all hashtags and finds the most popular ones."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Read *all* tweets. Don't bother with our time range; just try to capture as much content as possible.\n",
      "orgTweets = [json.load(open(twDir+f)) for f in os.listdir(twDir) if f != '.DS_Store']\n",
      "tweets = [tweet for org in orgTweets for tweet in org]\n",
      "hashtags = [tweet['entities']['hashtags'] for tweet in tweets]\n",
      "# del orgTweets, tweets\n",
      "hashtags = [ht['text'] for hashtagList in hashtags for ht in hashtagList]\n",
      "print 'Found %d hashtags.' % len(hashtags)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Found 27194 hashtags.\n"
       ]
      }
     ],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Process hashtag counts into a dictionary.\n",
      "htFreq = dict()\n",
      "for ht in hashtags:\n",
      "    if ht not in htFreq: htFreq[ht] = 0\n",
      "    htFreq[ht] += 1\n",
      "\n",
      "# Construct a data frame.\n",
      "htDf = pd.DataFrame(dict((k,[v]) for k,v in htFreq.iteritems())).transpose()\n",
      "htDf.columns = ['Incidence']\n",
      "# Order.\n",
      "htDf.sort('Incidence',ascending=False,inplace=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Print out top hashtags.\n",
      "print htDf.head(n=50)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "                       Incidence\n",
        "Ferguson                    1558\n",
        "Ebola                       1533\n",
        "BREAKING                    1386\n",
        "UPDATE                       760\n",
        "ISIS                         650\n",
        "Election2014                 471\n",
        "KellyFile                    394\n",
        "AFP                          330\n",
        "FoxNews                      314\n",
        "Obama                        253\n",
        "odd                          223\n",
        "msnbcvote                    219\n",
        "HongKong                     211\n",
        "FergusonDecision             202\n",
        "MichaelBrown                 185\n",
        "Syria                        183\n",
        "VIDEO                        181\n",
        "immigration                  169\n",
        "video                        157\n",
        "OscarPistorius               151\n",
        "Patriots                     148\n",
        "Hannity                      136\n",
        "GlobalCitizenFestival        131\n",
        "ebolaanswers                 122\n",
        "CometLanding                 121\n",
        "OccupyCentral                117\n",
        "Iraq                         105\n",
        "AC360                         99\n",
        "AP10Things                    98\n",
        "Thanksgiving                  92\n",
        "CNNElection                   89\n",
        "election2014                  85\n",
        "BBCSyriaWar                   83\n",
        "Ukraine                       81\n",
        "NFL                           81\n",
        "Apple                         79\n",
        "TIMEPOY                       78\n",
        "Midterms2014                  75\n",
        "DearPrudie                    75\n",
        "Iran                          75\n",
        "APracecall                    74\n",
        "indyref                       74\n",
        "mapoli                        74\n",
        "BlackFriday                   71\n",
        "Kobane                        70\n",
        "CNN                           67\n",
        "NBCPolitics                   66\n",
        "magov                         65\n",
        "WorldSeries                   63\n",
        "ebola                         63\n"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "From the above, there appear to be four major categories of hashtags:\n",
      "- Ferguson\n",
      "- ISIS, Syria/Iraq\n",
      "- Ebola\n",
      "- Midterm elections, Obama\n",
      "\n",
      "There are also some more notable topics:\n",
      "- Hong Kong\n",
      "- Immigration\n",
      "- Oscar Pistorius\n",
      "- Comet landing \n",
      "- Thanksgiving"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Idea: maybe examine the frequency of words found in all of these. \"Ebola\" will be in any post about Ebola, but we may want to hand-code a rule for election coverage, which may contain related words like \"vote\" or \"elect.\"**"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Hashtag Usage"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This analysis looks at how organizations are *using* hashtags. It may tell us if some don't at all, or which organizations are more prolific users."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Load all organizations for reference.\n",
      "orgs = json.load(open('../../conf/organizations.json'))\n",
      "# Container for stats.\n",
      "orgHtStats = dict()\n",
      "\n",
      "# Traverse orgs, collect hashtag stats.\n",
      "for org, oData in orgs.iteritems():\n",
      "    # Container for org stats.\n",
      "    stats = {\n",
      "        'hashtags': 0,\n",
      "        'tweetsWithHashtags': 0,\n",
      "    }\n",
      "    # Load all tweets, traverse and store stats.\n",
      "    tweets = json.load(open(twDir+[f for f in os.listdir(twDir) if f.startswith(org)][-1]))\n",
      "    for tweet in tweets:\n",
      "        htLen = len(tweet['entities']['hashtags'])\n",
      "        if htLen:\n",
      "            stats['hashtags'] += len(tweet['entities']['hashtags'])\n",
      "            stats['tweetsWithHashtags'] += 1\n",
      "    # Store some more stats.\n",
      "    # stats['usesHashtags'] = (stats['tweetsWithHashtags'] > 0)\n",
      "    stats['pctTweetsWithHashtags'] = float(stats['tweetsWithHashtags']) / len(tweets)\n",
      "    # Store in main container.\n",
      "    orgHtStats[oData['name']] = stats"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create dataframe, arrange, output.\n",
      "htStats = pd.DataFrame(orgHtStats).transpose()[[1,0,2]]\n",
      "htStats.sort('pctTweetsWithHashtags',ascending=False,inplace=True)\n",
      "print htStats"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "                     pctTweetsWithHashtags  hashtags  tweetsWithHashtags\n",
        "AFP                               0.502731      3074                2669\n",
        "Fox News                          0.465364      4443                2620\n",
        "CNN                               0.448348      2975                2157\n",
        "BBC                               0.375615      2880                2289\n",
        "MSNBC                             0.280266      1575                1433\n",
        "USA Today                         0.267586      1916                1552\n",
        "Boston Globe                      0.157367      1546                1272\n",
        "Yahoo News                        0.147313       987                 869\n",
        "NPR News                          0.130444       711                 584\n",
        "Wall Street Journal               0.127347       897                 841\n",
        "NBC News                          0.125561       556                 504\n",
        "Associated Press                  0.106198       653                 538\n",
        "CBS News                          0.103965       552                 472\n",
        "ABC News                          0.095481       495                 393\n",
        "Newsweek                          0.081901       525                 424\n",
        "Slate                             0.073493       689                 618\n",
        "LA Times                          0.072360       508                 405\n",
        "Reuters                           0.070290       380                 335\n",
        "The Daily Beast                   0.056208       335                 287\n",
        "Time                              0.037380       259                 222\n",
        "Huffington Post                   0.034949       508                 450\n",
        "The Guardian                      0.032482       423                 361\n",
        "The Daily Mail                    0.025799       122                 117\n",
        "Washington Post                   0.017442       117                 102\n",
        "NY Times                          0.008952        68                  67\n"
       ]
      }
     ],
     "prompt_number": 70
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Observations:\n",
      "- There is wide variation in hashtag usage.\n",
      "- The more \"sensational\" media\u2014cable news and USA Today\u2014are big on hashtags.\n",
      "- So are the AFP, the BBC, and the Globe. That's an odd bunch.\n",
      "\n",
      "**Hashtags may have predictive value. Maybe they represent \"engagement\" with the broader Twitter audience.**"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}