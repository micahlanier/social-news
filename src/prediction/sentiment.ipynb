{
 "metadata": {
  "name": "",
  "signature": "sha256:5f4dcf844be492d651dd573c881e1da6d37459f137894995f33280bc93a73c0c"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Sentiment and Predictive Analysis"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This notebook contains research into sentiment effects on predictive outcomes."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Setup"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "# Libraries.\n",
      "import json\n",
      "from matplotlib import pyplot as plt\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import pickle\n",
      "import seaborn as sns\n",
      "\n",
      "# Other settings.\n",
      "vizConf = json.load(open('../../conf/visualizations.json'))\n",
      "\n",
      "# Library settings.\n",
      "pd.options.display.max_columns = 50"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Data.\n",
      "tw = pd.read_csv('../../../data/unmergedPostSummaries/twitter.csv')\n",
      "fb = pd.read_csv('../../../data/unmergedPostSummaries/facebook.csv')\n",
      "\n",
      "# Track special columns.\n",
      "outcomeCols_lin = ['clicks','retweets','favorites','likes','shares','comments']\n",
      "twSpecificCols = set(tw.columns).difference(fb.columns)\n",
      "fbSpecificCols = set(fb.columns).difference(tw.columns)\n",
      "binaryCols = ['weekend_utc','weekend_est','retweeted']\n",
      "categoricalCols = binaryCols+['org','org_category','medium','agg_sentiment_class','sentiment_class','service','day_of_week_utc','day_of_week_est']\n",
      "\n",
      "# Calculate oscillations of time for regression.\n",
      "tw['time_est_sin'] = np.sin(tw['time_est'])\n",
      "tw['time_est_cos'] = np.cos(tw['time_est'])\n",
      "fb['time_est_sin'] = np.sin(fb['time_est'])\n",
      "fb['time_est_cos'] = np.cos(fb['time_est'])\n",
      "tw['minute_est_sin'] = np.sin(tw['minute_est'])\n",
      "tw['minute_est_cos'] = np.cos(tw['minute_est'])\n",
      "fb['minute_est_sin'] = np.sin(fb['minute_est'])\n",
      "fb['minute_est_cos'] = np.cos(fb['minute_est'])\n",
      "\n",
      "# Calculate normalized columns. Useful for comparisons.\n",
      "for o in twSpecificCols.intersection(outcomeCols_lin):\n",
      "    tw[o+'_normalized'] = tw[o].astype('float') / tw['followers_count'].astype('float')\n",
      "tw['clicks_normalized'] = tw['clicks'].astype('float') / tw['followers_count'].astype('float')\n",
      "for o in fbSpecificCols.intersection(outcomeCols_lin):\n",
      "    fb[o+'_normalized'] = fb[o].astype('float') / fb['account_likes'].astype('float')\n",
      "fb['clicks_normalized'] = fb['clicks'].astype('float') / fb['account_likes'].astype('float')\n",
      "\n",
      "# Log some outcomes.\n",
      "tw['clicks_log'] = np.log(tw['clicks'])\n",
      "fb['clicks_log'] = np.log(fb['clicks'])\n",
      "\n",
      "# Combine. Not all columns overlap.\n",
      "twfb = tw.append(fb)\n",
      "\n",
      "# Generate categorical columns.\n",
      "for c in categoricalCols:\n",
      "    dummyVals = pd.get_dummies(twfb[c])\n",
      "    dummyVals.columns = [c+'_'+str(val) for val in dummyVals.columns]\n",
      "    twfb.merge(dummyVals.iloc[:,1:], left_index=True, right_index=True)\n",
      "    if c not in fbSpecificCols:\n",
      "        dummyVals_tw = pd.get_dummies(tw[c])\n",
      "        dummyVals_tw.columns = [c+'_'+str(val) for val in dummyVals_tw.columns]\n",
      "        tw = tw.merge(dummyVals_tw.iloc[:,1:], left_index=True, right_index=True)\n",
      "    if c not in twSpecificCols:\n",
      "        dummyVals_fb = pd.get_dummies(fb[c])\n",
      "        dummyVals_fb.columns = [c+'_'+str(val) for val in dummyVals_fb.columns]\n",
      "        fb = fb.merge(dummyVals_fb.iloc[:,1:], left_index=True, right_index=True, copy=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Features.\n",
      "features_lm_tw = (\n",
      "    ['time_est','time_est_sin','time_est_cos','time_est_2','time_est_3','minute_est','minute_est_sin','minute_est_cos','minute_est_2','minute_est_3',\n",
      "     'followers_count','hashtags','sentiment_score_negative','sentiment_score_positive','word_count'] +\n",
      "    [f for f in tw.columns if f.startswith((\n",
      "        'day_of_week_est_', 'org_', 'medium_', 'sentiment_class_'\n",
      "    )) and not f.startswith('org_category')]\n",
      ")\n",
      "features_lm_fb = (\n",
      "    ['time_est','time_est_sin','time_est_cos','time_est_2','time_est_3','minute_est','minute_est_sin','minute_est_cos','minute_est_2','minute_est_3',\n",
      "     'account_likes','agg_sentiment_score_negative','agg_sentiment_score_positive','sentiment_score_negative','sentiment_score_positive','word_count'] +\n",
      "    [f for f in fb.columns if f.startswith((\n",
      "        'day_of_week_est_', 'org_', 'medium_','agg_sentiment_class_', 'sentiment_class_'\n",
      "    )) and not f.startswith('org_category')]\n",
      ")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Load prior regression models.\n",
      "lm_clicks_tw = pickle.load(open('../../../data/models/clicks/lm_clicks_tw.pkl'))\n",
      "lm_clicks_fb = pickle.load(open('../../../data/models/clicks/lm_clicks_fb.pkl'))\n",
      "lm_retweets  = pickle.load(open('../../../data/models/retweets/lm_retweets.pkl'))\n",
      "lm_likes  = pickle.load(open('../../../data/models/retweets/lm_likes.pkl'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Twitter"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Examine sentiment effect on links."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Duplicate tweets.\n",
      "twAdjusted = tw\n",
      "\n",
      "# Augment sentiment scores.\n",
      "# Use random numbers to generate classes of augmentations (positive or negative).\n",
      "randomPositives = np.random.binomial(n=1,p=0.5,size=len(twAdjusted))\n",
      "randomNegatives = (1 - randomPositives)\n",
      "\n",
      "# Update sentiment scores.\n",
      "twAdjusted.sentiment_score_positive = twAdjusted.sentiment_score_positive + 0.125*randomPositives\n",
      "twAdjusted.sentiment_score_negative = twAdjusted.sentiment_score_negative + 0.125*randomPositives\n",
      "\n",
      "# Update sentiment classes.\n",
      "twAdjusted.sentiment_class = twAdjusted.sentiment_score_positive + 0.125*randomPositives"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}